{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "### cuML\n",
    "\n",
    "cuML is a suite of libraries that implement machine learning algorithms and mathematical primitives functions that share compatible APIs with other RAPIDS projects.\n",
    "\n",
    "cuML enables data scientists, researchers, and software engineers to run traditional tabular ML tasks on GPUs without going into the details of CUDA programming. In most cases, cuML's Python API matches the API from scikit-learn.\n",
    "\n",
    "For large datasets, these GPU-based implementations can complete 10-50x faster than their CPU equivalents. For details on performance, see the cuML Benchmarks Notebook.\n",
    "    \n",
    "[GitHub](https://github.com/rapidsai/cuml) | [Welcome Notebook](../welcome.ipynb#Machine-Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlazingContext ready\n"
     ]
    }
   ],
   "source": [
    "from blazingsql import BlazingContext\n",
    "\n",
    "# connect to BlazingSQL w/ BlazingContext API\n",
    "bc = BlazingContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyblazing.apiv2.context.BlazingTable at 0x7fe885b023d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# identify path to data directory\n",
    "data_dir = f'{os.getcwd().split(\"/intro_notebooks\")[0]}/data'\n",
    "\n",
    "# create a BlazingSQL table from any file w/ .create_table(table_name, file_path)\n",
    "bc.create_table('taxi', f'{data_dir}/sample_taxi.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.82 s, sys: 343 ms, total: 2.16 s\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from cuml import LinearRegression\n",
    "from cuml.preprocessing.model_selection import train_test_split\n",
    "\n",
    "# pull feature (X) and target (y) values\n",
    "X = bc.sql('SELECT trip_distance, tolls_amount FROM taxi')\n",
    "y = bc.sql('SELECT fare_amount FROM taxi')['fare_amount']\n",
    "\n",
    "# split data into train and test sets (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 421 ms, sys: 97 ms, total: 518 ms\n",
      "Wall time: 541 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# call Linear Regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# train the model\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test X values\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2145465529140157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# convert test & predicted values .to_pandas() & find the model's r2_score\n",
    "r2_score(y_true=y_test.to_pandas(), y_pred=y_pred.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "from cuml.cluster import DBSCAN\n",
    "\n",
    "# Create and populate a GPU DataFrame\n",
    "gdf_float = cudf.DataFrame()\n",
    "gdf_float['0'] = [1.0, 2.0, 5.0]\n",
    "gdf_float['1'] = [4.0, 2.0, 1.0]\n",
    "gdf_float['2'] = [4.0, 2.0, 1.0]\n",
    "\n",
    "# Setup and fit clusters\n",
    "dbscan_float = DBSCAN(eps=1.0, min_samples=1)\n",
    "dbscan_float.fit(gdf_float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-GPU \n",
    "\n",
    "cuML also features multi-GPU and multi-node-multi-GPU operation, using Dask, for a growing list of algorithms. \n",
    "\n",
    "The following Python snippet reads input from a CSV file and performs a NearestNeighbors query across a cluster of Dask workers, using multiple GPUs on a single node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dask CUDA cluster w/ one worker per device\n",
    "from dask_cuda import LocalCUDACluster\n",
    "cluster = LocalCUDACluster()\n",
    "\n",
    "# Read CSV file in parallel across workers\n",
    "import dask_cudf\n",
    "df = dask_cudf.read_csv(\"/path/to/csv\")\n",
    "\n",
    "# Fit a NearestNeighbors model and query it\n",
    "from cuml.dask.neighbors import NearestNeighbors\n",
    "nn = NearestNeighbors(n_neighbors = 10)\n",
    "nn.fit(df)\n",
    "neighbors = nn.kneighbors(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAPIDS Stable",
   "language": "python",
   "name": "rapids-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
